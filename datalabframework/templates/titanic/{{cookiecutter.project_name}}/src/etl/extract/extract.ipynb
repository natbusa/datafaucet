{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datalabframework as dlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/natbusa/Projects/dsp-titanic/src'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlf.project.rootpath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engines:\n",
      "  spark:\n",
      "    config:\n",
      "      jobname: default\n",
      "      master: local[1]\n",
      "    context: spark\n",
      "loggers:\n",
      "  kafka:\n",
      "    enable: false\n",
      "    hosts:\n",
      "    - localhost:29092\n",
      "    severity: info\n",
      "    topic: dlf\n",
      "  stream:\n",
      "    enable: true\n",
      "    severity: info\n",
      "providers:\n",
      "  local:\n",
      "    rootpath: ../data\n",
      "    service: fs\n",
      "resources:\n",
      "  .etl.clean.test:\n",
      "    format: parquet\n",
      "    path: datasets/clean/test\n",
      "    provider: local\n",
      "  .etl.clean.train:\n",
      "    format: parquet\n",
      "    path: datasets/clean/train\n",
      "    provider: local\n",
      "  .etl.extract.test:\n",
      "    format: parquet\n",
      "    path: datasets/extract/test\n",
      "    provider: local\n",
      "  .etl.extract.train:\n",
      "    format: parquet\n",
      "    path: datasets/extract/train\n",
      "    provider: local\n",
      "  .etl.features.test:\n",
      "    format: parquet\n",
      "    path: datasets/features/test\n",
      "    provider: local\n",
      "  .etl.features.train:\n",
      "    format: parquet\n",
      "    path: datasets/features/train\n",
      "    provider: local\n",
      "  .etl.raw.test:\n",
      "    format: csv\n",
      "    path: datasets/raw/test.csv\n",
      "    provider: local\n",
      "  .etl.raw.train:\n",
      "    format: csv\n",
      "    path: datasets/raw/train.csv\n",
      "    provider: local\n",
      "run: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = dlf.params.metadata()\n",
    "dlf.utils.pretty_print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine = dlf.engines.get('spark')\n",
    "spark = engine.context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark:2.3.1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out name and version\n",
    "'{}:{}'.format(engine.info['context'], spark.sparkSession.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Survived     Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.raw.train', header=True, inferSchema=True)\n",
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine.write(df, '.etl.extract.train', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null or NaN values, and count them per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "df = engine.read('.etl.raw.test', header=True, inferSchema=True)\n",
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "engine.write(df,'.etl.extract.test', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId  Integer    True\n",
      "Pclass       Integer    True\n",
      "Name         String     True\n",
      "Sex          String     True\n",
      "Age          Double     True\n",
      "SibSp        Integer    True\n",
      "Parch        Integer    True\n",
      "Ticket       String     True\n",
      "Fare         Double     True\n",
      "Cabin        String     True\n",
      "Embarked     String     True\n"
     ]
    }
   ],
   "source": [
    "for column in df.schema:\n",
    "    print('{:<12} {:<10} {}'.format(column.name, str(column.dataType)[:-4], column.nullable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null or NaN values, and count them per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from etl.features.features import describe_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|summary|       PassengerId|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare|Cabin|Embarked|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "|  count|               418|               418|                 418|   418|               332|               418|               418|               418|               417|   91|     418|\n",
      "|   mean|            1100.5|2.2655502392344498|                null|  null|30.272590361445783|0.4473684210526316|0.3923444976076555|223850.98986486485|  35.6271884892086| null|    null|\n",
      "| stddev|120.81045760473994|0.8418375519640503|                null|  null|14.181209235624424|0.8967595611217135|0.9814288785371694| 369523.7764694362|55.907576179973844| null|    null|\n",
      "|    min|               892|                 1|\"Assaf Khalil, Mr...|female|              0.17|                 0|                 0|            110469|               0.0|  A11|       C|\n",
      "|    max|              1309|                 3|van Billiard, Mas...|  male|              76.0|                 8|                 9|       W.E.P. 5734|          512.3292|   G6|       S|\n",
      "+-------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "| summary|       PassengerId|            Pclass|                Name|   Sex|               Age|             SibSp|             Parch|            Ticket|              Fare| Cabin|Embarked|\n",
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "|     nan|                 0|                 0|                   0|     0|                 0|                 0|                 0|                 0|                 0|     0|       0|\n",
      "|  isnull|                 0|                 0|                   0|     0|                86|                 0|                 0|                 0|                 1|   327|       0|\n",
      "|    type|           Integer|           Integer|              String|String|            Double|           Integer|           Integer|            String|            Double|String|  String|\n",
      "|distinct|               418|                 3|                 418|     2|                79|                 7|                 8|               363|               169|    76|       3|\n",
      "|   count|               418|               418|                 418|   418|               332|               418|               418|               418|               417|    91|     418|\n",
      "|    mean|            1100.5|2.2655502392344498|                None|  None|30.272590361445783|0.4473684210526316|0.3923444976076555|223850.98986486485|  35.6271884892086|  None|    None|\n",
      "|  stddev|120.81045760473994|0.8418375519640503|                None|  None|14.181209235624424|0.8967595611217135|0.9814288785371694| 369523.7764694362|55.907576179973844|  None|    None|\n",
      "|     min|               892|                 1|\"Assaf Khalil, Mr...|female|              0.17|                 0|                 0|            110469|               0.0|   A11|       C|\n",
      "|     max|              1309|                 3|van Billiard, Mas...|  male|              76.0|                 8|                 9|       W.E.P. 5734|          512.3292|    G6|       S|\n",
      "+--------+------------------+------------------+--------------------+------+------------------+------------------+------------------+------------------+------------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe_all(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
