version: '2'
services:
  concourse-db:
    image: postgres
    environment:
    - POSTGRES_DB=concourse
    - POSTGRES_PASSWORD=concourse
    - POSTGRES_USER=concourse
    volumes:
      - ./volumes/concourse:/var/lib/postgresql/data

  concourse:
    image: concourse/concourse
    command: quickstart
    privileged: true
    depends_on: [concourse-db]
    ports: ["8088:8080"]
    environment:
    - CONCOURSE_POSTGRES_HOST=concourse-db
    - CONCOURSE_POSTGRES_USER=concourse
    - CONCOURSE_POSTGRES_PASSWORD=concourse
    - CONCOURSE_POSTGRES_DATABASE=concourse
    - CONCOURSE_EXTERNAL_URL
    - CONCOURSE_ADD_LOCAL_USER=test:$$2a$$10$$0W9/ilCpYXY/yCPpaOD.6eCrGda/fnH3D4lhsw1Mze0WTID5BuiTW
    - CONCOURSE_MAIN_TEAM_ALLOW_ALL_USERS=true
    - CONCOURSE_WORKER_GARDEN_NETWORK

  postgres:
    image: postgres
    volumes:
      - ./volumes/postgres:/var/lib/postgresql/data
      - ./postgres/data:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: root
      POSTGRES_USER: postgres

  mysql:
    image: mysql
    command: --default-authentication-plugin=mysql_native_password
    ports:
      - "3306:3306"
    volumes:
      - ./volumes/mysql:/var/lib/mysql
      - ./mysql/data:/docker-entrypoint-initdb.d
    environment:
      MYSQL_ROOT_PASSWORD: root

  redis:
    image: redis
    restart: always
    volumes:
      - ./volumes/redis:/data

  cassandra:
    image: cassandra
    restart: always
    volumes:
      - ./volumes/cassandra:/var/lib/cassandra
    environment:
      - DS_LICENSE=accept
      - MAX_HEAP_SIZE=256M
      - HEAP_NEWSIZE=64M

  jupyter:
    build: jupyter
    command: start.sh jupyter lab
    volumes:
      - ./jupyter:/home/jovyan
    environment:
      SPARK_OPTS: '--master=spark://spark-master:7077'
    ports:
      - 8888:8888

  zookeeper:
    image: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zookeeper:2888:3888

  kafka:
    image: wurstmeister/kafka
    ports:
      - 9092:9092
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "datalabframework:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper

  elasticsearch:
    build: elasticsearch/
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"

  logstash:
    build: logstash/
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    depends_on:
      - elasticsearch
      - kafka

  kibana:
    build: kibana/
    volumes:
      - ./kibana/config/:/usr/share/kibana/config
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  spark-master:
    image: jupyter/pyspark-notebook
    command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    hostname: spark-master
    environment:
      MASTER: spark://spark-master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 4040
      - 6066
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 8080:8080
    volumes:
      - ./spark/conf/master:/conf
      - ./volumes/spark/master/data:/tmp/data

  spark-worker-1:
    image: jupyter/pyspark-notebook
    command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-1
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8081:8081
    volumes:
      - ./spark/conf/worker:/conf
      - ./volumes/spark/worker-1/data:/tmp/data
      - ./volumes/spark/worker-1/work:/usr/local/spark/work

  spark-worker-2:
    image: jupyter/pyspark-notebook
    command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    hostname: spark-worker-2
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
    ports:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8082:8081
    volumes:
      - ./spark/conf/worker:/conf
      - ./volumes/spark/worker-2/data:/tmp/data
      - ./volumes/spark/worker-2/work:/usr/local/spark/work

  hdfs-nn:
    image: itrust/hdfs:2.7.1
    hostname: hdfs-nn
    command: /run-namenode.sh
    volumes:
      - ./volumes/hdfs/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-nn:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
    ports:
      - 50070:50070

  hdfs-dn:
    image: itrust/hdfs:2.7.1
    links:
        - hdfs-nn
    command: /run-datanode.sh
    volumes:
      - ./volumes/hdfs/datanode:/hadoop/dfs/data
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-nn:8020
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false

  minio-1:
    image: minio/minio:RELEASE.2018-09-12T18-49-56Z
    volumes:
      - ./volumes/minio/1/data:/data
      - ./volumes/minio/1/config:/root/.minio
    ports:
      - "9001:9000"
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server  http://minio-1/data http://minio-2/data http://minio-3/data  http://minio-4/data

  minio-2:
    image: minio/minio:RELEASE.2018-09-12T18-49-56Z
    volumes:
      - ./volumes/minio/2/data:/data
      - ./volumes/minio/2/config:/root/.minio
    ports:
      - "9002:9000"
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server  http://minio-1/data http://minio-2/data http://minio-3/data  http://minio-4/data

  minio-3:
    image: minio/minio:RELEASE.2018-09-12T18-49-56Z
    volumes:
      - ./volumes/minio/3/data:/data
      - ./volumes/minio/3/config:/root/.minio
    ports:
      - "9003:9000"
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server  http://minio-1/data http://minio-2/data http://minio-3/data  http://minio-4/data

  minio-4:
    image: minio/minio:RELEASE.2018-09-12T18-49-56Z
    volumes:
      - ./volumes/minio/4/data:/data
      - ./volumes/minio/4/config:/root/.minio
    ports:
      - "9004:9000"
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server  http://minio-1/data http://minio-2/data http://minio-3/data http://minio-4/data
